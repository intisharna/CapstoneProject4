{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "85cb5b0a",
      "metadata": {
        "id": "85cb5b0a"
      },
      "source": [
        "# Pelatihan Model Vehicle Detection\n",
        "\n",
        "**Tujuan:** Melatih model YOLO berbasis Deep Learning untuk mendeteksi 3 kelas: bus, car, dan van."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c85d0bd",
      "metadata": {
        "id": "7c85d0bd"
      },
      "source": [
        "## Menghubungkan ke Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5c7ad585",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7ad585",
        "outputId": "b05583db-5996-47e6-b8c4-cd3c7dc25ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menghubungkan ke Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive berhasil terhubung di /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "print(\"Menghubungkan ke Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive berhasil terhubung di /content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdd8674",
      "metadata": {
        "id": "dfdd8674"
      },
      "source": [
        "## Setup dan Ekstrak Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9b3b274f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b3b274f",
        "outputId": "ebe22bb4-bfed-47b6-fb37-1c2527f2a9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Membaca '/content/drive/MyDrive/Capstone Project JCAI/Capstone 4/dataset.zip' dari Google Drive...\n",
            "Mengekstrak ke folder ./vehicle_dataset...\n",
            "Ekstraksi selesai.\n",
            "\n",
            "Memeriksa isi folder 'vehicle_dataset':\n",
            "vehicle_dataset/\n",
            "    vehicle-detection.v1i.yolov12/\n",
            "        README.dataset.txt\n",
            "        data.yaml\n",
            "        README.roboflow.txt\n",
            "        train/\n",
            "            labels/\n",
            "                Screenshot-2025-04-07-182941_png.rf.1cc0f750fce15ab92293e7ff073f7aa3.txt\n",
            "                image-78-_jpeg_jpg.rf.4b798b4311c13dfb940790293b4cd230.txt\n",
            "                Screenshot-2025-04-08-110134_png.rf.9f02859111f568994967aa97e52cadfc.txt\n",
            "                -66F945A5-3856-4F91-9EDD-6EF4833F57FA-png_jpg.rf.dafd08d9cca9cd5e6ded8e10d4f8340e.txt\n",
            "                Screenshot-2025-04-02-151144_png.rf.a353fa7f073ea2600c174e78a347dced.txt\n",
            "                ...\n",
            "            images/\n",
            "                -5A06964D-6D40-4132-A769-F21A3B8E1DAA-png_jpg.rf.774d2dec838f2999a3579e0a76832691.jpg\n",
            "                tyoto_minivan1273_png.rf.40b5163ec7ba2e2b8318448829df483c.jpg\n",
            "                modified_image_70_jpg.rf.fe8871ed231708e5da29334385bb36b7.jpg\n",
            "                bus-193-_jpg.rf.0f00065150a85d896801611082623962.jpg\n",
            "                dealers-0000101-G9N-MPic_jpg.rf.7169e9d85ebd32ca029bdd95529a86c7.jpg\n",
            "                ...\n",
            "        valid/\n",
            "            labels/\n",
            "                -152B35A7-2687-4126-B46B-5382319E7A3C-png_jpg.rf.3ab9604b74f8b8dc06f57e7045f9c330.txt\n",
            "                -400E9E90-CD4A-470F-89E2-C9E1D1854AAB-png_jpg.rf.edf276f32d4e7299af3049008066739c.txt\n",
            "                tyoto_minivan1498_png.rf.25a73a02a927b00c07575b772d9af658.txt\n",
            "                -DF6ABE64-1B3B-4148-A35F-D957221C40B7-png_jpg.rf.9344637f2c9b8a1ec7269171a97b0633.txt\n",
            "                25d550cb70b99743_jpg.rf.a3d8157f387f869d3c6802ccdb6e29f0.txt\n",
            "                ...\n",
            "            images/\n",
            "                -26A4102E-9D99-421D-91DC-9E66089FF2F6-png_jpg.rf.7430ef9466b1134edc0e5cf0d96ee1ed.jpg\n",
            "                youtube-46_jpg.rf.f2594fe98c2407a73a60e08652b5a0c0.jpg\n",
            "                bus-158-_jpg.rf.08a91d0b43635eed47a21d0206cb18ec.jpg\n",
            "                Screenshot-2025-04-02-150024_png.rf.9ef820c1e047ddf073359e8060d6221d.jpg\n",
            "                bus-187-_jpg.rf.53d0857e5153100e341e57cd67975ff1.jpg\n",
            "                ...\n",
            "        test/\n",
            "            -0DEDC30B-FD9A-4A41-ABC0-DBEDE7C1C712-png_jpg.rf.9a2be641c09957ab79fc0a2a544df032.jpg\n",
            "            -0DEDC30B-FD9A-4A41-ABC0-DBEDE7C1C712-png_jpg.rf.cfac1f8e298433d62e027d5e2b28da39.jpg\n",
            "            labels/\n",
            "                -2846226C-6A55-4876-B717-7F8A5FA4E560-png_jpg.rf.94c50b9a3890930ae4357a9c5eb888a2.txt\n",
            "                Screenshot-2025-04-07-212536_png.rf.2ab4a51a89f09369356b296b2fef00c9.txt\n",
            "                WhatsApp-Image-2022-12-05-at-18-16-49_jpeg_jpg.rf.0818c2387d16ba0f2cea8e22e398d780.txt\n",
            "                talyer-repair-shop-without-parking-01-1673411477_jpg.rf.a97c47a0ac3bd7b4270c08f8c30dc744.txt\n",
            "                Screenshot-2025-04-02-145922_png.rf.9f12b65269c8970d3729a120d5bf9177.txt\n",
            "                ...\n",
            "            images/\n",
            "                bus-57-_jpg.rf.397821964a0f8967273f27adb84a7000.jpg\n",
            "                modified_img1_48_jpg.rf.dc2b4a8b810cd256efaf69f0bcfcdaf1.jpg\n",
            "                tyoto_minivan1587_png.rf.c4f55fe7ef3ce1d19d2973a5fd8be103.jpg\n",
            "                -046E9840-F025-4749-B3AB-19402B34E739-png_jpg.rf.ccbd26a1031345facc1b539e776da48a.jpg\n",
            "                -11F0AF93-D3D0-4415-A4A0-B3430EA0886B-png_jpg.rf.58c6f4b533ad8d718101b53335d898dd.jpg\n",
            "                ...\n",
            "    __MACOSX/\n",
            "        ._vehicle-detection.v1i.yolov12\n",
            "        vehicle-detection.v1i.yolov12/\n",
            "            ._test\n",
            "            ._valid\n",
            "            ._train\n",
            "            ._README.roboflow.txt\n",
            "            ._data.yaml\n",
            "            ...\n",
            "            train/\n",
            "                ._labels\n",
            "                ._images\n",
            "                labels/\n",
            "                    ._WhatsApp-Image-2022-12-05-at-18-21-42_jpeg_jpg.rf.2fb83052869ba11816e87984c94df176.txt\n",
            "                    ._880px-Jinbei_Haise_MK6_002_jpg.rf.a46f88314184195a07914073774b3609.txt\n",
            "                    ._Screenshot-2025-04-02-190945_png.rf.89cb20a1acfc3365c642140af48b2a2b.txt\n",
            "                    ._Screenshot-2025-04-07-212059_png.rf.df33f0434c171a6e00bac0cbb7f178ba.txt\n",
            "                    ._modified_image_99_jpg.rf.4853b077d0939b870c4591f84caee613.txt\n",
            "                    ...\n",
            "                images/\n",
            "                    ._tyoto_minivan1604_png.rf.17cd1c821669ecd75b60059ec5f65677.jpg\n",
            "                    ._img-00654_jpg.rf.d2166095a649ab3373fb7976ca6259c3.jpg\n",
            "                    ._tyoto_minivan204_png.rf.a9f81007cbb56363b44aa2d348946e12.jpg\n",
            "                    ._A-22-_png.rf.860b05f42768bd8b947acc0b41f3b3d4.jpg\n",
            "                    ._200_jpg.rf.43023320afb52494c73b22778443e284.jpg\n",
            "                    ...\n",
            "            valid/\n",
            "                ._labels\n",
            "                ._images\n",
            "                labels/\n",
            "                    ._bus-68-_jpg.rf.333d3a85ea1bc16dab02f09a86475582.txt\n",
            "                    ._tyoto_minivan1498_png.rf.25a73a02a927b00c07575b772d9af658.txt\n",
            "                    ._Screenshot-2025-04-07-184041_png.rf.cdd49b386f644dc54d38876787173538.txt\n",
            "                    ._-50894A9D-DA2D-4049-9C7B-6006F32452BC-png_jpg.rf.2814b38abf2fb26dce4819908db607a0.txt\n",
            "                    ._youtube-52_jpg.rf.b4d93383521043df35b9a1039cafe4ed.txt\n",
            "                    ...\n",
            "                images/\n",
            "                    ._Screenshot-2025-04-07-205805_png.rf.a11afe702842cd863eab2b11eda06154.jpg\n",
            "                    ._Screenshot-2025-04-02-145008_png.rf.e30990f607c9271e6cb8e06f7d1008b6.jpg\n",
            "                    ._-3B056DBB-3097-4BCB-A38A-F66FA7470A6C-png_jpg.rf.4f5643056515c97f3cd104cd5d9c07d6.jpg\n",
            "                    ._bus-109-_jpg.rf.cfc7dde6fb63d06713b39776ddb01830.jpg\n",
            "                    ._bus-214-_jpg.rf.aa3437ebc8de7683ebb239fa8090a7eb.jpg\n",
            "                    ...\n",
            "            test/\n",
            "                ._labels\n",
            "                ._-0DEDC30B-FD9A-4A41-ABC0-DBEDE7C1C712-png_jpg.rf.9a2be641c09957ab79fc0a2a544df032.jpg\n",
            "                ._images\n",
            "                ._-0DEDC30B-FD9A-4A41-ABC0-DBEDE7C1C712-png_jpg.rf.cfac1f8e298433d62e027d5e2b28da39.jpg\n",
            "                labels/\n",
            "                    ._es-march-due-to-coronavirus-pandemic-jeepneys-were-allowed-operate-214763913_jpg.rf.661d3bbb48e25a6330cd7b723d0dc189.txt\n",
            "                    ._tyoto_minivan177_png.rf.3601b2526e5845fdce23e21be8a7c04e.txt\n",
            "                    ._modified1_img1_2_jpg.rf.47e00808c8e18a07e83fc838cba44954.txt\n",
            "                    ._Screenshot-2025-04-07-220144_png.rf.1825117c20a1820ec8a763c77c3d167a.txt\n",
            "                    ._IMG_20250325_113114_jpg.rf.d83a0141d0d8d5fd5384931f41b0332b.txt\n",
            "                    ...\n",
            "                images/\n",
            "                    ._talyer-repair-shop-without-parking-01-1673411477_jpg.rf.a97c47a0ac3bd7b4270c08f8c30dc744.jpg\n",
            "                    ._bus-14-_jpg.rf.1ab806f9d36c7d2891be3815a5964708.jpg\n",
            "                    ._Screenshot-2025-04-07-184610_png.rf.b7348355b7718eba299c4de0f015491a.jpg\n",
            "                    ._modified_image_89_jpg.rf.a6fc13baa20c5c949c68cbef2153b534.jpg\n",
            "                    ._bus-188-_jpg.rf.580dc27447b98992c9bd12d3315e3266.jpg\n",
            "                    ...\n"
          ]
        }
      ],
      "source": [
        "%pip install -q ultralytics supervision pandas\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "ZIP_FILE = \"/content/drive/MyDrive/Capstone Project JCAI/Capstone 4/dataset.zip\"\n",
        "# ---------------------------\n",
        "\n",
        "DATASET_DIR = \"vehicle_dataset\"\n",
        "\n",
        "if os.path.exists(ZIP_FILE):\n",
        "    print(f\"Membaca '{ZIP_FILE}' dari Google Drive...\")\n",
        "    print(f\"Mengekstrak ke folder ./{DATASET_DIR}...\")\n",
        "    with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATASET_DIR)\n",
        "    print(\"Ekstraksi selesai.\")\n",
        "\n",
        "    print(f\"\\nMemeriksa isi folder '{DATASET_DIR}':\")\n",
        "    for root, dirs, files in os.walk(DATASET_DIR):\n",
        "        level = root.replace(DATASET_DIR, '').count(os.sep)\n",
        "        indent = ' ' * 4 * (level)\n",
        "        print(f'{indent}{os.path.basename(root)}/')\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "\n",
        "        for f in files[:5]:\n",
        "            print(f'{subindent}{f}')\n",
        "        if len(files) > 5:\n",
        "            print(f'{subindent}...')\n",
        "\n",
        "\n",
        "else:\n",
        "    print(f\"ERROR: File '{ZIP_FILE}' tidak ditemukan di Google Drive.\")\n",
        "    print(\"Pastikan Anda sudah mengunggah 'dataset.zip' ke Google Drive dan path-nya benar.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFlXUkdePKK2",
        "outputId": "b19e1098-bf69-43cf-ac83-1bad1e63c17c"
      },
      "id": "aFlXUkdePKK2",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37e368b8",
      "metadata": {
        "id": "37e368b8"
      },
      "source": [
        "## Konfigurasi Data Pipeline (data.yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "60fae331",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60fae331",
        "outputId": "6d789688-9798-4a00-aeaa-f77d01b92df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File config.yaml berhasil dibuat.\n",
            "--- Isi config.yaml ---\n",
            "names:\n",
            "- bus\n",
            "- car\n",
            "- van\n",
            "nc: 3\n",
            "path: /content/vehicle_dataset/vehicle-detection.v1i.yolov12\n",
            "test: test/images\n",
            "train: train/images\n",
            "val: valid/images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "BASE_DATASET_PATH = os.path.join(os.path.abspath(DATASET_DIR), 'vehicle-detection.v1i.yolov12')\n",
        "\n",
        "data_config = {\n",
        "    'path': '.', # Set path to current directory or empty to avoid confusion with absolute paths below\n",
        "    'train': os.path.join(BASE_DATASET_PATH, 'train/images'),\n",
        "    'val': os.path.join(BASE_DATASET_PATH, 'valid/images'),\n",
        "    'test': os.path.join(BASE_DATASET_PATH, 'test/images'),\n",
        "    'nc': 3,\n",
        "    'names': ['bus', 'car', 'van']\n",
        "}\n",
        "\n",
        "# Verification for debugging\n",
        "print(f\"Verifying paths in config.yaml before writing:\")\n",
        "print(f\"  Full train path: {data_config['train']} exists: {os.path.exists(data_config['train'])}\")\n",
        "print(f\"  Full val path:   {data_config['val']} exists: {os.path.exists(data_config['val'])}\")\n",
        "print(f\"  Full test path:  {data_config['test']} exists: {os.path.exists(data_config['test'])}\")\n",
        "# End Verification\n",
        "\n",
        "CONFIG_FILE = \"config.yaml\"\n",
        "with open(CONFIG_FILE, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"File {CONFIG_FILE} berhasil dibuat.\")\n",
        "print(\"--- Isi config.yaml ---\")\n",
        "with open(CONFIG_FILE, 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43286592",
      "metadata": {
        "id": "43286592"
      },
      "source": [
        "## Pelatihan (Transfer Learning) & Augmentasi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7689f7fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7689f7fe",
        "outputId": "392f4e2c-57b8-49c2-af81-ce7a3b261c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.0, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv12n summary: 272 layers, 2,568,633 parameters, 2,568,617 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 640/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2126.1Â±555.6 MB/s, size: 81.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/vehicle_dataset/vehicle-detection.v1i.yolov12/train/labels.cache... 9218 images, 15 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9218/9218 13.0Mit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 84, len(boxes) = 18494. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 271.7Â±142.7 MB/s, size: 20.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/vehicle_dataset/vehicle-detection.v1i.yolov12/valid/labels.cache... 287 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 287/287 74.5Kit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 19, len(boxes) = 427. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train6\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      3.34G       1.38      1.893      1.617          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.0it/s 3:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.6s/it 14.1s\n",
            "                   all        287        427      0.229      0.323      0.181     0.0923\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50       3.5G      1.311      1.611       1.58          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.7it/s 2.4s\n",
            "                   all        287        427      0.295      0.315      0.231      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50       3.5G      1.173       1.41      1.458          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.528      0.526      0.503      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50       3.5G      1.087      1.281      1.388          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.519      0.507      0.524      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50       3.5G      1.013      1.163      1.326          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.657      0.572      0.647       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50       3.5G     0.9533      1.065      1.273          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.649      0.629      0.704      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50       3.5G     0.9095      1.003      1.239          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        287        427      0.684      0.669      0.702       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50       3.5G     0.8757     0.9481      1.219          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.637       0.62       0.66      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50       3.5G     0.8514     0.9054      1.197          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.2it/s 3:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.2s\n",
            "                   all        287        427      0.729      0.698      0.751       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50       3.5G     0.8298     0.8841      1.182          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.655      0.655      0.721      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50       3.5G     0.8121      0.841      1.163          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.2it/s 3:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.772      0.675      0.768      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50       3.5G     0.8004     0.8239      1.157          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.2it/s 3:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.3s\n",
            "                   all        287        427      0.768       0.69      0.776      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50       3.5G     0.7766       0.78      1.144          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.2s\n",
            "                   all        287        427      0.719      0.702       0.74      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50       3.5G     0.7633     0.7553      1.138          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        287        427      0.735      0.697      0.779      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50       3.5G     0.7479     0.7398      1.121          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        287        427      0.805      0.614       0.77      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50       3.5G     0.7375     0.7126      1.113          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.2s\n",
            "                   all        287        427      0.816       0.71      0.808      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50       3.5G     0.7296     0.7055       1.11          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.752      0.731      0.811      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50       3.5G     0.7177     0.6778      1.101          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        287        427      0.767      0.775      0.817      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50       3.5G     0.6986     0.6627      1.088          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.766      0.688      0.793      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50       3.5G     0.6937     0.6456      1.082          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.2s\n",
            "                   all        287        427      0.786       0.78      0.807       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50       3.5G     0.6775     0.6215      1.074          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        287        427      0.805      0.757      0.834      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50       3.5G     0.6771     0.6033      1.068          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.2s\n",
            "                   all        287        427      0.845        0.7      0.809      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50       3.5G      0.661     0.5991      1.061          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427       0.85      0.773       0.84      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50       3.5G      0.655     0.5874      1.053          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.816      0.769      0.837      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50       3.5G     0.6453     0.5664      1.052          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        287        427       0.83      0.809      0.839      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50       3.5G     0.6345     0.5527      1.041          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.3s\n",
            "                   all        287        427      0.844       0.78      0.843      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50       3.5G     0.6258     0.5363      1.035          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.856      0.771      0.831      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50       3.5G     0.6216     0.5288      1.035          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427       0.84      0.798      0.849      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50       3.5G     0.6098     0.5066      1.024          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        287        427      0.832      0.812      0.855      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50       3.5G     0.6061     0.5027      1.024          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.2s\n",
            "                   all        287        427      0.867      0.727      0.833      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50       3.5G      0.603     0.4931      1.023          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.843      0.737      0.821      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50       3.5G     0.5923     0.4841      1.014          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.855      0.764      0.831      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50       3.5G     0.5866     0.4685      1.012          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        287        427      0.854      0.796      0.833      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50       3.5G     0.5743     0.4582      1.004          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427       0.86      0.845      0.861      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50       3.5G     0.5678     0.4471     0.9994          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.804      0.824      0.844      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50       3.5G     0.5627     0.4414     0.9942          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        287        427      0.811      0.835      0.834      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50       3.5G     0.5606     0.4343      0.996          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.792      0.862      0.847      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50       3.5G     0.5522     0.4224     0.9897          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        287        427      0.807      0.807      0.837      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50       3.5G      0.543     0.4158     0.9815          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.2it/s 2:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.765      0.829      0.824       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50       3.5G     0.5354     0.4034     0.9807          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.2s\n",
            "                   all        287        427      0.851      0.801      0.835      0.638\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50       3.5G     0.5308     0.3987      0.974          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        287        427      0.831      0.814      0.845      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50       3.5G      0.524     0.3889      0.972          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.809      0.838      0.834      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50       3.5G     0.5175     0.3816     0.9678          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.3it/s 2:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        287        427      0.809       0.83       0.83      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50       3.5G     0.5137     0.3751     0.9654          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 577/577 3.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        287        427      0.831      0.806      0.833      0.638\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 34, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "44 epochs completed in 2.160 hours.\n",
            "Optimizer stripped from /content/runs/detect/train6/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/runs/detect/train6/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/runs/detect/train6/weights/best.pt...\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,557,313 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.5s\n",
            "                   all        287        427       0.86      0.844       0.86      0.665\n",
            "                   bus         67        113      0.958      0.813      0.912      0.669\n",
            "                   car        211        279      0.931      0.776      0.894       0.67\n",
            "                   van         30         35      0.691      0.943      0.775      0.656\n",
            "Speed: 0.2ms preprocess, 4.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train6\u001b[0m\n",
            "Pelatihan selesai.\n"
          ]
        }
      ],
      "source": [
        "model = YOLO('yolo12n.pt')\n",
        "\n",
        "# Latih model\n",
        "results = model.train(\n",
        "    data=CONFIG_FILE,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    patience=10,\n",
        "    batch=16,\n",
        "    optimizer='AdamW',\n",
        "\n",
        "    hsv_h=0.015,  # Perubahan Hue (warna)\n",
        "    hsv_s=0.7,    # Perubahan Saturation\n",
        "    hsv_v=0.4,    # Perubahan kecerahan/kontras\n",
        "    erasing=0.4,  # Simulasi noise\n",
        "\n",
        "    fliplr=0.0,   # Flip horizontal\n",
        "    degrees=0.0,  # Rotasi\n",
        "    mosaic=0.0    # Mosaic\n",
        ")\n",
        "\n",
        "print(\"Pelatihan selesai.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff4d3318",
      "metadata": {
        "id": "ff4d3318"
      },
      "source": [
        "## Evaluasi Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "40d9659e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40d9659e",
        "outputId": "9e7042dd-2327-4b9e-ff48-546819bae9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mengevaluasi model pada test set...\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,557,313 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1212.2Â±869.8 MB/s, size: 47.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/vehicle_dataset/vehicle-detection.v1i.yolov12/test/labels.cache... 220 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 220/220 126.0Kit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 14, len(boxes) = 413. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.0it/s 4.6s\n",
            "                   all        220        413      0.869      0.784      0.875      0.683\n",
            "                   bus         67        109      0.859      0.781      0.894      0.663\n",
            "                   car        133        236      0.912       0.79      0.863      0.641\n",
            "                   van         58         68      0.838      0.779      0.868      0.745\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "--- Metrik Evaluasi Akhir (Test Set) ---\n",
            "mAP@0.5:0.95 (Metrik Utama): 68.29%\n",
            "mAP@0.5 (Metrik Sekunder): 87.52%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "MODEL_TERBAIK_PATH = 'runs/detect/train6/weights/best.pt'\n",
        "\n",
        "if os.path.exists(MODEL_TERBAIK_PATH):\n",
        "    model_terbaik = YOLO(MODEL_TERBAIK_PATH)\n",
        "\n",
        "    print(\"Mengevaluasi model pada test set...\")\n",
        "    metrics = model_terbaik.val(split='test')\n",
        "\n",
        "    print(\"--- Metrik Evaluasi Akhir (Test Set) ---\")\n",
        "    print(f\"mAP@0.5:0.95 (Metrik Utama): {metrics.box.map * 100:.2f}%\")\n",
        "    print(f\"mAP@0.5 (Metrik Sekunder): {metrics.box.map50 * 100:.2f}%\")\n",
        "else:\n",
        "    print(f\"ERROR: Pelatihan gagal atau model '{MODEL_TERBAIK_PATH}' tidak ditemukan.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan Model ke Google Drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "PATH_MODEL_ASLI = 'runs/detect/train6/weights/best.pt'\n",
        "\n",
        "PATH_TUJUAN_GDRIVE = '/content/drive/MyDrive/best_model_intishar.pt'\n",
        "\n",
        "if os.path.exists(PATH_MODEL_ASLI):\n",
        "    print(f\"Menyalin model terbaik dari {PATH_MODEL_ASLI} ke Google Drive\")\n",
        "    shutil.copy(PATH_MODEL_ASLI, PATH_TUJUAN_GDRIVE)\n",
        "    print(f\"Selesai. Model Anda sekarang aman di: {PATH_TUJUAN_GDRIVE}\")\n",
        "else:\n",
        "    print(f\"ERROR: Tidak dapat menemukan {PATH_MODEL_ASLI}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWv6rDWpwCBp",
        "outputId": "3a1feb56-8d36-4a58-d697-e7cf1c1e8586"
      },
      "id": "EWv6rDWpwCBp",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menyalin model terbaik dari runs/detect/train6/weights/best.pt ke Google Drive\n",
            "Selesai. Model Anda sekarang aman di: /content/drive/MyDrive/best_model_intishar.pt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}